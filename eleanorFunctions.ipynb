{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "setupFlag = False ## Set flag to True if these aren't installed\n",
    "if setupFlag:\n",
    "    !{sys.executable} -m pip install astroquery\n",
    "    ## https://github.com/astropy/astroquery\n",
    "    !{sys.executable} -m pip install eleanor\n",
    "    ## https://github.com/afeinstein20/eleanor\n",
    "    !{sys.executable} -m pip install lightkurve\n",
    "    ## https://github.com/KeplerGO/lightkurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import dis\n",
    "import inspect\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import astropy\n",
    "import astroquery\n",
    "import eleanor\n",
    "#import tess_stars2px ## Currently unnecessary\n",
    "import lightkurve as lk\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy as sp\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.time import Time\n",
    "from astropy.time import TimeDelta\n",
    "from astropy.timeseries import TimeSeries\n",
    "from astropy.visualization import time_support\n",
    "time_support()\n",
    "from astropy.visualization import quantity_support\n",
    "quantity_support()\n",
    "\n",
    "from scipy import linalg as la\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "from scipy import stats\n",
    "\n",
    "from IPython.display import display_html\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(directory): ## creates a directory if it doesn't exist\n",
    "    ## credit to https://gist.github.com/keithweaver/562d3caa8650eefe7f84fa074e9ca949\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "def display_side_by_side(*args): ##displays pandas DataFrames side by side\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n",
    "\n",
    "def unravel(list): ## creates an array from a list of arrays\n",
    "    return np.array([i for array in list for i in array])\n",
    "\n",
    "savePNG = True ## Changes matplotlib backend to save plots as pgf (default:True)\n",
    "if savePNG:\n",
    "    mpl.use(\"agg\")\n",
    "    plotExt = str('.png')\n",
    "elif not savePNG:\n",
    "    mpl.use(\"pgf\")\n",
    "    mpl.rcParams.update({\n",
    "        \"pgf.texsystem\": \"pdflatex\",\n",
    "        'font.family': 'serif',\n",
    "        'text.usetex': True,\n",
    "        'pgf.rcfonts': False,})\n",
    "    plotExt = str('.pgf')\n",
    "\n",
    "notebookPlotFlag = True ## Changes Jupyter plotting backend (default:True)\n",
    "if notebookPlotFlag:\n",
    "    %matplotlib notebook\n",
    "elif not notebookPlotFlag:\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpToMatch(item1,item2):\n",
    "    ## Function takes two pandas DataFrames with a 'time' column (float or integer type)\n",
    "    ## and interpolates the data to match the set with a smaller number of points\n",
    "    ## with the interpolated DataFrames being returned as a tuple\n",
    "    item1_indexed = item1.set_index('time')\n",
    "    item2_indexed = item2.set_index('time')\n",
    "    #display(item1_indexed)\n",
    "    item1_length = len(item1_indexed.index)\n",
    "    item2_length = len(item2_indexed.index)\n",
    "    #display(item1_length)\n",
    "    if item1_length >= item2_length:\n",
    "        minun = item2_indexed.index.min()\n",
    "        plusle = item2_indexed.index.max()\n",
    "        numPoints = item2_length\n",
    "    elif item1_length <= item2_length:\n",
    "        minun = item1_indexed.index.min()\n",
    "        plusle = item1_indexed.index.max()\n",
    "        numPoints = item1_length\n",
    "    #display(minun)\n",
    "    #display(plusle)\n",
    "    \n",
    "    #numPoints = abs(plusle-minun)\n",
    "    newIndex = np.linspace(minun,plusle-1,numPoints)\n",
    "    #display(numPoints)\n",
    "    #display(newIndex)\n",
    "    \n",
    "    item1_interp = pd.DataFrame(index=newIndex)\n",
    "    item1_interp.index.name = item1_indexed.index.name\n",
    "    item2_interp = pd.DataFrame(index=newIndex)\n",
    "    item2_interp.index.name = item2_indexed.index.name\n",
    "\n",
    "    for colname, col in item1_indexed.iteritems():\n",
    "        item1_interp[colname] = np.interp(newIndex,item1_indexed.index,col)\n",
    "    for colname, col in item2_indexed.iteritems():\n",
    "        item2_interp[colname] = np.interp(newIndex,item2_indexed.index,col)\n",
    "    item1_interp.reset_index(inplace=True)\n",
    "    item2_interp.reset_index(inplace=True)\n",
    "    \n",
    "    return item1_interp, item2_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpToData(data, *args):\n",
    "    ## More generalized version of interpToMatch(). Takes an argument for a reference\n",
    "    ## DataFrame and a variable number of DataFrames to be interpolated so that\n",
    "    ## they match the time sampling of the reference DataFrame. Like interpToMatch(),\n",
    "    ## DataFrames must have a 'time' column of an integer or float type.\n",
    "    ## Function returns an array containing the reference DataFrame as the first\n",
    "    ## item followed by the interpolated DataFrames in the order in which they were\n",
    "    ## passed to the function\n",
    "    interpArray = []\n",
    "    interpArray.append(data)\n",
    "    \n",
    "    data_indexed = data.set_index('time')\n",
    "    data_length = len(data_indexed.index)\n",
    "    minun = data_indexed.index.min()\n",
    "    plusle = data_indexed.index.max()\n",
    "    newIndex = data_indexed.index\n",
    "    \n",
    "    for arg in args:\n",
    "        arg_indexed = arg.set_index('time')\n",
    "        arg_interp = pd.DataFrame(index=newIndex)\n",
    "        arg_interp.index.name = arg_indexed.index.name\n",
    "        for colname, col in arg_indexed.iteritems():\n",
    "            arg_interp[colname] = np.interp(newIndex,arg_indexed.index,col)\n",
    "        arg_interp.reset_index(inplace=True)\n",
    "        interpArray.append(arg_interp)\n",
    "    return interpArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snStats(radec, peak, sector=None, tpfSize=23, apRad=1,\n",
    "            plot=True, savePlot=False, targetName=None, verbose=False):\n",
    "    ## Uses eleanor to search for target SN in TESS field and identifies if peak is observed\n",
    "    ## during a given sector. Function returns both the converted number of days\n",
    "    ## relative to the estimated peak as well as the lightkurve object produced\n",
    "    ## for the source.\n",
    "    \n",
    "    ## radec is taken as string in form 'hh mm ss +dd mm ss'\n",
    "    ## peak is taken as string in form 'yyyy-mm-dd hh:mm:ss' or 'yyyy-mm-dd' (ie iso format)\n",
    "    ## sector is taken as integer between 1-23, signifying which sector is of interest \n",
    "    ##     Note: if sector argument is not called, function will identify the most\n",
    "    ##     recent sector when the target was viewed. Not all objects are viewed in all \n",
    "    ##     sectors, Eleanor documentation explains how one can determine what sectors an \n",
    "    ##     object is viewed in.\n",
    "    ## tpfSize is taken as an integer and is the size of produced target pixel file in pixels \n",
    "    ##     Note: must be an odd number, defaults to 23 pixels as that seems to be the size used\n",
    "    ##     in Vallely et al.\n",
    "    ## plot is taken as a boolean and plots the tpf and the flux relative to the estimated peak\n",
    "    ## savePlot is taken as a boolean and saves the plots to a local folder\n",
    "    ## targetName is taken as a string and alters plot titles and save directory\n",
    "    ##     Note: if targetName is not provided, plots will be labeled as the identified TIC\n",
    "    ##     of the object and, if savePlot is True, the directory for saved plots will be\n",
    "    ##     named according to the TIC as well.\n",
    "    ## verbose is taken as a boolean and will return various statistics about the observation\n",
    "    \n",
    "    ## Note: should try to make it so there's an argument that allows for the auto-aperture to be used\n",
    "    ## Note: should remove dependence on lightkurve and swap to using pandas DataFrames\n",
    "    \n",
    "    coords = SkyCoord(radec,unit=(u.hourangle,u.deg));\n",
    "    if sector:\n",
    "        target = eleanor.Source(coords=coords,sector=sector);\n",
    "    elif not sector:\n",
    "        target = eleanor.Source(coords=coords);\n",
    "    data = eleanor.TargetData(target, height=tpfSize, width=tpfSize, do_psf=False, do_pca=False);\n",
    "    \n",
    "#     eleanor.TargetData.custom_aperture(data, shape='circle', r=apRad, method='exact')\n",
    "#     eleanor.TargetData.get_lightcurve(data)\n",
    "    \n",
    "    ticCoords = SkyCoord(ra=target.coords[0],dec=target.coords[1],unit=(u.deg,u.deg))\n",
    "    #time.sleep(0.15) ## originally in place due to file caching issues, re-enable if these are encountered\n",
    "    peakTime = Time(peak, format='iso')\n",
    "    obsStartTime = lk.utils.btjd_to_astropy_time(data.time)[0]\n",
    "    obsEndTime = lk.utils.btjd_to_astropy_time(data.time)[-1]\n",
    "    peakTimePres = obsStartTime.jd <= peakTime.jd <= obsEndTime.jd\n",
    "    if not peakTimePres:\n",
    "        timeDiff = np.around(-peakTime.to_value('jd') + \n",
    "                             min([obsStartTime.to_value('jd'), obsEndTime.to_value('jd')], \n",
    "                                 key=lambda x:abs(x-peakTime.to_value('jd'))),2)\n",
    "        print(\"Warning: provided peak is \"+str(timeDiff)+\" days outside of TESS time range\")\n",
    "    q = data.quality == 0    \n",
    "    lc = data.to_lightkurve(flux=data.raw_flux+0.1*data.flux_bkg)\n",
    "    daysFromPeak = lk.utils.btjd_to_astropy_time(lc.time) - peakTime.jd \n",
    "    obsPeak = Time(np.str(lc.time[np.argmax(lc.flux)]+2457000),format='jd')\n",
    "    \n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"Target Name: \"+targetName if targetName else \"\")\n",
    "        print(\"TESS Input Catalog (TIC) ID: \"+str(target.tic))\n",
    "        print(\"Located at: \"+ticCoords.to_string('hmsdms'), end=\" \")\n",
    "        print(\"(exact target)\" if ticCoords.ra==coords.ra and \n",
    "              ticCoords.dec==coords.dec else \"(closest target)\")\n",
    "        print(\"TESS Sector: \"+str(target.sector))\n",
    "        print(\"Observation Start: \"+obsStartTime.iso)\n",
    "        print(\"Observation End: \"+obsEndTime.iso)\n",
    "        print(\"Observation Length: \"+\n",
    "              str(np.around(obsEndTime.to_value('jd') - obsStartTime.to_value('jd'),3))+' days')\n",
    "        print(\"Peak Flux of \"+str(np.around(np.max(lc.flux),3))+\n",
    "              \" e/s Observed on \"+str(obsPeak.iso))\n",
    "        print()\n",
    "    if plot:\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(15,4))\n",
    "        ax1.imshow(data.tpf[0])\n",
    "        ax1.set_title('Target Pixel File')\n",
    "        ax2.imshow(data.bkg_tpf[0])\n",
    "        ax2.set_title('2D interpolated background')\n",
    "        ax3.imshow(data.aperture)\n",
    "        ax3.set_title('Aperture')\n",
    "        plotTitle = str(targetName+' (TIC '+\n",
    "                        str(target.tic)+')') if targetName else str(\"Identified Target (TIC \"\n",
    "                                                                        +str(target.tic)+\")\")\n",
    "        fig.suptitle(plotTitle)\n",
    "        if savePlot:\n",
    "            saveDir = str(\"./\"+targetName+\"/\") if targetName else str(\"./TIC \"+str(target.tic)+\"/\")\n",
    "            mkdir(saveDir)\n",
    "            fig.savefig(saveDir+\"TPF\"+plotExt, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(daysFromPeak, lc.flux, color=(0,0.6,0.5), label=\"Lightcurve\")\n",
    "        ## originally plotted the maximum value of the flux, disabled\n",
    "        ## because it is currently dominated by points at the start of\n",
    "        ## TESS' orbit. May be brought back after that data is excluded\n",
    "        #plt.axvline(x=daysFromPeak.jd[np.argmax(lc.flux)], color=(0,0,0),\n",
    "                   #linestyle='dotted', label='Max Flux: '+str(np.around(np.max(lc.flux),3))+' e/s')\n",
    "        if peakTimePres:\n",
    "            plt.axvline(x=0, color=(0.8,0.4,0), \n",
    "                        linestyle='dashed', label='Estimated Peak')\n",
    "        plt.locator_params(axis='x', nbins=10)\n",
    "        plt.xticks(rotation=20)\n",
    "        plt.xlabel('Days From Estimated Peak')\n",
    "        plt.ylabel('Flux(e/s)')\n",
    "        plt.legend()\n",
    "        plt.title(plotTitle)\n",
    "        if savePlot:\n",
    "            saveDir = str(\"./\"+targetName+\"/\") if targetName else str(\"./TIC \"+str(target.tic)+\"/\")\n",
    "            mkdir(saveDir)\n",
    "            fig.savefig(saveDir+\"lightcurve\"+plotExt, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "    return [daysFromPeak, lc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optBackground(t, initGuess=0.2, plot=True):\n",
    "    ## Function finds the optimal percentage of background flux to add back in to match results of Vallely et al.\n",
    "    ## for ASASSN-18tb by using a chi squared penalty function\n",
    "    ## t is taken as a tuple, where the two terms are the min and max day values over which to optimize the penalty\n",
    "    ## function\n",
    "    ## initGuess is the first guess for the percent of background flux to add back in (should be around 0.00-0.50)\n",
    "    ## Note: would possibly be good to generalize this function in the event that data from other papers on \n",
    "    ## other supernovae can be found\n",
    "    \n",
    "    paperCurve = pd.read_csv('asassn18tb_TESS_Sector1.txt',delim_whitespace=True,header=0,names=[\"time\",\"counts\",\"error\"])\n",
    "    paperCurve['counts_median'] = paperCurve['counts'].rolling(12).median()\n",
    "    paperCurve['error_median'] = paperCurve['error'].rolling(12).median()\n",
    "    t0 = t[0]\n",
    "    t1 = t[1]\n",
    "\n",
    "    source = eleanor.Source(coords=SkyCoord('04 18 06.149 âˆ’63 36 56.68',\n",
    "                                    unit=(u.hourangle,u.deg)),sector=1)\n",
    "    data = eleanor.TargetData(source,height=17,width=17,\n",
    "                         do_psf=False,do_pca=True)\n",
    "    eleanorCurve = pd.DataFrame()\n",
    "    q = data.quality == 0\n",
    "    eleanorCurve[\"time\"] = data.time[q]\n",
    "    eleanorCurve[\"raw_flux\"] = data.raw_flux[q]\n",
    "    eleanorCurve['raw_counts'] = data.raw_flux[q] * 1800\n",
    "    eleanorCurve['raw_counts_median'] = eleanorCurve['raw_counts'].rolling(12).median()\n",
    "    eleanorCurve[\"bkg_flux\"] = data.flux_bkg[q]\n",
    "    eleanorCurve['bkg_counts'] = data.flux_bkg[q] * 1800\n",
    "    eleanorCurve[\"raw_flux_err\"] = data.flux_err[q]\n",
    "    eleanorCurve['zp_flux'] = eleanorCurve['raw_flux'] - eleanorCurve['raw_flux'].median()\n",
    "    eleanorCurve['zp_bkg_flux'] = eleanorCurve['bkg_flux'] - eleanorCurve['bkg_flux'].median()\n",
    "    eleanorCurve['zp_counts'] = eleanorCurve['zp_flux'] * 1800\n",
    "    eleanorCurve['zp_counts_median'] = eleanorCurve['zp_counts'].rolling(12).median()\n",
    "    eleanorCurve['zp_bkg_counts'] = eleanorCurve['zp_bkg_flux'] * 1800\n",
    "\n",
    "    interp_paperCurve = interpToData(eleanorCurve,paperCurve)[1]\n",
    "    trim_eleanorCurve = eleanorCurve.loc[(eleanorCurve[\"time\"] >= t0) & (eleanorCurve[\"time\"] <= t1)]\n",
    "    trim_paperCurve = interp_paperCurve.loc[(interp_paperCurve['time'] >= t0) & (interp_paperCurve['time'] <= t1)]\n",
    "    #display(trim_paperCurve)\n",
    "    chiSq = lambda x:  np.sum((((trim_eleanorCurve['zp_counts'] + x*trim_eleanorCurve['zp_bkg_counts'])\n",
    "                      - (trim_paperCurve['counts']))/trim_paperCurve['error'] )**2)\n",
    "    bkgScale = optimize.fmin(chiSq,initGuess)[0]\n",
    "    print()\n",
    "    eleanorCurve['corr_flux'] = eleanorCurve['zp_flux'] + bkgScale * eleanorCurve['zp_bkg_flux']\n",
    "    eleanorCurve['corr_counts'] = eleanorCurve['corr_flux'] * 1800\n",
    "    eleanorCurve['corr_counts_median'] = eleanorCurve['corr_counts'].rolling(12).median()\n",
    "    \n",
    "    if plot:\n",
    "        ax = paperCurve.plot(x='time',y='counts',color='blue',alpha=0.1,kind='scatter')\n",
    "        paperCurve.plot(x='time',y='counts_median',color='blue',linewidth=2,label='Vallely et al.',ax=ax)\n",
    "        eleanorCurve.plot(x='time',y='zp_counts',color='red',alpha=0.1,kind='scatter',ax=ax)\n",
    "        eleanorCurve.plot(x='time',y='zp_counts_median',color='red',linewidth=2,label='Raw TESS Observations',ax=ax)\n",
    "        eleanorCurve.plot(x='time',y='corr_counts',color='green',alpha=0.1,kind='scatter',ax=ax)\n",
    "        eleanorCurve.plot(x='time',y='corr_counts_median',color='green',linewidth=2,label='Corrected TESS Observations',ax=ax)\n",
    "        plt.axvline(x=t0,color='black',linestyle='--',label=\"Sampled Region\")\n",
    "        plt.axvline(x=t1,color='black',linestyle='--')\n",
    "        #plt.tight_layout()\n",
    "        plt.ylabel('counts')\n",
    "        plt.legend()\n",
    "        plt.title('Optimisation of eleanor Background Subtraction \\n for ASASSN-18tb (scale: '+str(bkgScale)+')')\n",
    "    return eleanorCurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
